import json
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed

# ------------------ vLLM SERVER ------------------
client = OpenAI(
    base_url="http://0.0.0.0:8002/v1",   # your vLLM endpoint
    api_key="not-needed"
)

MODEL_ID = "deepseek"       # your served-model-name
MAX_CONCURRENCY = 43        # from your vLLM limits


# ------------------ CHAT CALL ------------------
def generate_chat(query: str, trace: str):

    # minimal payload (no temperature, top_p, max_tokens, seed)
    payload = {
        "model": MODEL_ID,
        "messages": [
            {
                "role": "user",
                "content": f"{query} and {trace}"
            }
        ]
    }

    try:
        res = client.chat.completions.create(**payload)
        return res.choices[0].message["content"]
    except Exception as e:
        return f"ERROR: {str(e)}"


# ------------------ PROCESS DATASET ------------------
def process_dataset(dataset_path: str, output_path: str):

    # Load dataset.json
    with open(dataset_path, "r") as f:
        dataset = json.load(f)

    all_results = {}

    for list_id, items in dataset.items():
        print(f"\n========= Processing List {list_id} =========")

        list_results = []

        # create thread pool
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENCY) as executor:

            futures = {
                executor.submit(generate_chat, item["query"], item["trace"]): item
                for item in items
            }

            for future in as_completed(futures):
                item = futures[future]
                query, trace = item["query"], item["trace"]

                try:
                    answer = future.result()
                except Exception as e:
                    answer = f"ERROR: {str(e)}"

                list_results.append({
                    "query": query,
                    "trace": trace,
                    "response": answer
                })

        all_results[list_id] = list_results

    # save outputs
    with open(output_path, "w") as f:
        json.dump(all_results, f, indent=2)

    print(f"\nDONE. Saved output to {output_path}")


# ------------------ RUN ------------------
if __name__ == "__main__":
    process_dataset(
        dataset_path="dataset.json",     # your input file
        output_path="outputs.json"       # output file
    )
