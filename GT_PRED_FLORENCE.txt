def yolov8_postprocess(outputs, conf_threshold=0.25, iou_threshold=0.45, max_detections=300, reg_max=16):
    """
    outputs: [B, 72, 8400] -> DFL(64) + class(8)
    returns list of detections per image: [N,6]
    """
    B, C, HW = outputs.shape
    nc = C - 4 * reg_max  # = 8

    outputs = outputs.permute(0, 2, 1)       # (B,HW,72)

    # Split
    pred_dist = outputs[:, :, :4 * reg_max]   # DFL bins
    pred_cls  = outputs[:, :, 4 * reg_max:]   # Class logits

    # Decode DFL into box distances (l,t,r,b)
    dfl = dfl_decode(pred_dist, reg_max=reg_max)   # (B,HW,4)

    # Convert distances to box corners
    # Detect module generates anchor points, but your postprocess needs absolute coords.
    # Here we assume anchors already applied (training forward uses detect())
    # So DFL gives x1,y1,x2,y2 directly
    boxes = dfl

    # Class scores
    class_probs = torch.sigmoid(pred_cls)

    results = []

    for b in range(B):
        scores, labels = class_probs[b].max(dim=1)

        mask = scores > conf_threshold
        if mask.sum() == 0:
            results.append(torch.zeros((0, 6)))
            continue

        bboxes = boxes[b][mask]
        scores = scores[mask]
        labels = labels[mask]

        keep = classwise_nms(bboxes, scores, labels, iou_threshold)

        keep = keep[:max_detections]

        det = torch.cat([
            bboxes[keep],
            scores[keep].unsqueeze(1),
            labels[keep].float().unsqueeze(1)
        ], dim=1)

        results.append(det)

    return results




@torch.no_grad()
def validate_model(model, val_loader, device="cuda", conf=0.25, iou_thres=0.5):
    model.eval()
    tp = fp = fn = 0
    correct_cls = 0
    total_cls = 0

    for imgs4, labels in tqdm(val_loader, desc="Validating"):
        imgs4 = imgs4.to(device)
        H, W = imgs4.shape[2], imgs4.shape[3]

        # 1. Get detect output
        feats = model.forward_features(imgs4)
        raw = model.detect(feats)

        preds = yolov8_postprocess(raw, conf_threshold=conf)

        for i, det in enumerate(preds):
            gt = labels[i].to(device)  # [N,5]

            if gt.numel() == 0:
                if det.size(0) > 0:
                    fp += det.size(0)
                continue

            # Convert GT to pixel coords
            gx = gt[:,1] * W
            gy = gt[:,2] * H
            gw = gt[:,3] * W
            gh = gt[:,4] * H

            x1 = gx - gw/2; y1 = gy - gh/2
            x2 = gx + gw/2; y2 = gy + gh/2
            gt_box = torch.stack([x1,y1,x2,y2], dim=1)

            # Predictions
            if det.size(0) == 0:
                fn += gt.size(0)
                continue

            pred_box = det[:, :4]
            pred_cls = det[:, 5].long()

            # IoU matching
            iou = box_iou(pred_box, gt_box)
            max_iou, idx = iou.max(dim=1)

            match = max_iou > iou_thres

            tp += match.sum().item()
            fp += (~match).sum().item()
            fn += gt.size(0) - match.sum().item()

            # Class accuracy
            matched_gt_cls = gt[idx][match][:,0].long()
            matched_pred_cls = pred_cls[match]

            correct_cls += (matched_pred_cls == matched_gt_cls).sum().item()
            total_cls += matched_pred_cls.numel()

    map50 = tp / (tp + fp + 1e-6)
    cls_acc = correct_cls / (total_cls + 1e-6)

    return map50, cls_acc
