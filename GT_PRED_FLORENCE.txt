import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import numpy as np

# ------------------------------
# YOLO Dataset (simple version)
# ------------------------------
class YoloDataset(Dataset):
    def __init__(self, img_dir, label_dir, img_size=640):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_size = img_size
        self.img_files = sorted([
            f for f in os.listdir(img_dir)
            if f.lower().endswith((".jpg", ".png", ".jpeg"))
        ])

    def __len__(self):
        return len(self.img_files)

    def __getitem__(self, idx):
        img_name = self.img_files[idx]
        img_path = os.path.join(self.img_dir, img_name)
        label_path = os.path.join(self.label_dir, img_name.replace('.jpg', '.txt').replace('.png', '.txt'))

        # Load image (no augmentation, resize only)
        img = Image.open(img_path).convert("RGB")
        img = img.resize((self.img_size, self.img_size))
        img = np.array(img) / 255.0
        img = torch.tensor(img, dtype=torch.float32).permute(2,0,1)  # [3,H,W]

        # Load labels
        targets = []
        if os.path.exists(label_path):
            with open(label_path, "r") as f:
                for line in f:
                    cls, x, y, w, h = map(float, line.strip().split())
                    targets.append([cls, x, y, w, h])

        targets = torch.tensor(targets, dtype=torch.float32) if len(targets) else torch.zeros((0,5))

        return img, targets


# ------------------------------
# Collate (simple)
# ------------------------------
def collate_fn(batch):
    imgs = torch.stack([b[0] for b in batch])   # [B,3,H,W]
    labels = [b[1] for b in batch]              # list([N_i,5])
    return imgs, labels


# ------------------------------
# Training Loop (MINIMAL)
# ------------------------------
def train(model, loss_fn, dataloader, device, epochs=10, save_path="yolov8_custom.pt"):
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    for epoch in range(epochs):
        model.train()
        total_loss = 0

        for imgs, targets in dataloader:
            imgs = imgs.to(device)
            
            # Convert list-of-targets â†’ YOLOv8 format: [img_idx, cls, x, y, w, h]
            batch_labels = []
            for i, t in enumerate(targets):
                if len(t) > 0:
                    img_idx = torch.full((t.shape[0], 1), i, dtype=torch.float32)
                    batch_labels.append(torch.cat((img_idx, t), dim=1))
            batch_labels = torch.cat(batch_labels, dim=0).to(device) if batch_labels else torch.zeros((0,6)).to(device)

            # Forward
            preds = model(imgs)

            # Loss
            loss, _ = loss_fn(preds, batch_labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"Epoch {epoch+1}/{epochs}  Loss: {total_loss:.4f}")

    torch.save(model.state_dict(), save_path)
    print("Saved model:", save_path)
