import json
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed

client = OpenAI(
    base_url="http://0.0.0.0:8002/v1",
    api_key="not-needed"
)

MODEL_ID = "deepseek"
MAX_CONCURRENCY = 43


def generate_chat(query: str, trace: str):
    payload = {
        "model": MODEL_ID,
        "messages": [
            {"role": "user", "content": f"{query} and {trace}"}
        ]
    }

    try:
        res = client.chat.completions.create(**payload)
        return res.choices[0].message.content
    except Exception as e:
        return f"ERROR: {str(e)}"


def process_dataset(dataset_path: str, output_path: str):

    # Load input dataset
    with open(dataset_path, "r") as f:
        dataset = json.load(f)

    # Load previous partial outputs if the file exists (resume)
    try:
        with open(output_path, "r") as f:
            saved_output = json.load(f)
    except FileNotFoundError:
        saved_output = {}

    for list_id, items in dataset.items():

        # Skip if already completed earlier
        if str(list_id) in saved_output:
            print(f"Skipping list {list_id} (already completed).")
            continue

        print(f"\n========= Processing List {list_id} =========")

        list_results = []

        # Process items concurrently
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENCY) as executor:
            futures = {
                executor.submit(generate_chat, item["query"], item["trace"]): item
                for item in items
            }

            for future in as_completed(futures):
                item = futures[future]
                query = item["query"]
                trace = item["trace"]

                try:
                    answer = future.result()
                except Exception as e:
                    answer = f"ERROR: {str(e)}"

                list_results.append({
                    "query": query,
                    "trace": trace,
                    "response": answer
                })

        # Save JUST this list immediately
        saved_output[str(list_id)] = list_results

        with open(output_path, "w") as f:
            json.dump(saved_output, f, indent=2)

        print(f"Saved list {list_id} to {output_path}")

    print("\nAll done!")
